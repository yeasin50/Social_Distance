{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imageSearch.centroidtracker import CentroidTracker\n",
    "from imageSearch.trackableobject import TrackableObject\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " imutils.video  will help us to work with a webcam and to calculate the estimated Frames Per Second (FPS) throughput rate   \n",
    " dlib  library will be used for its correlation tracker implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -p PROTOTXT -m MODEL [-i INPUT] [-o OUTPUT] [-c CONFIDENCE] [-s SKIP_FRAMES]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -p/--prototxt, -m/--model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
    "\thelp=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-i\", \"--input\", type=str,\n",
    "\thelp=\"path to optional input video file\")\n",
    "ap.add_argument(\"-o\", \"--output\", type=str,\n",
    "\thelp=\"path to optional output video file\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.4,\n",
    "\thelp=\"minimum probability to filter weak detections\")\n",
    "ap.add_argument(\"-s\", \"--skip-frames\", type=int, default=30,\n",
    "\thelp=\"# of skip frames between detections\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\t\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\t\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\t\"sofa\", \"train\", \"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] init model...\n"
     ]
    }
   ],
   "source": [
    "srcPath = r'videos/example_01.mp4'\n",
    "protoTxtPath = r'YOLO_DB/MobileNetSSD_deploy.prototxt'\n",
    "modelPath = r'YOLO_DB/MobileNetSSD_deploy.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] init model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] init model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(protoTxtPath, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(srcPath)\n",
    "writer = None\n",
    "width = None\n",
    "height = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CentroidTracker(maxDisappeared=50, maxDistance=50)\n",
    "trackers = []\n",
    "trackableObjects= {} # map each unique object ID to a TrackableObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the total number of objects that have moved either up or down\n",
    "totalFrames = 0\n",
    "totalDown = 0\n",
    "totalUp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the frames per second throughput estimator\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, img = cam.read()\n",
    "    \n",
    "    if img is None:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"video\", img)\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
